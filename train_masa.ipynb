{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from src.dataset.coco import get_coco\n",
    "import src.dataset.DatasetReader as DatasetReader\n",
    "import matplotlib.pyplot as plt\n",
    "import src.dataset.utils as utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6\n",
      "True\n",
      "True\n",
      "True\n",
      "NVIDIA GeForce RTX 3080\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)  # Check CUDA version PyTorch was built with\n",
    "print(torch.cuda.is_available())  # Check if PyTorch recognizes CUDA\n",
    "print(torch.backends.cudnn.enabled)  # Check if cuDNN is available\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.get_device_name(0))  # Should show RTX 3060\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\projects\\lpcv\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "e:\\projects\\lpcv\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532797\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "])\n",
    "\n",
    "dataset = DatasetReader.COCODataset(annotation_file='../data/annotations/annotations/instances_train2017.json',\n",
    "    image_dir= '../data/train2017/train2017',\n",
    "    target_classes=[s.lower() for s in utils.GLOBAL_CLASSES],\n",
    "    transform=transform)\n",
    "\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=11, prefetch_factor=4, persistent_workers=True)\n",
    "\n",
    "model = models.mobilenet_v3_small(pretrained=True)\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 64)  \n",
    "model = model.to(device)\n",
    "\n",
    "print(len(dataset))\n",
    "print(dataset[90001][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00002)\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "        asdf = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {running_loss / len(dataloader):.4f}, Time: {asdf:.4f}s\")\n",
    "        torch.save(model.state_dict(), f\"model_{epoch}epoha_coco_train_batch_size_{batch_size}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# run this to train the model \n",
    "# train_model(model, dataloader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "- treba da se stavi da koristi validacioni dataaset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slika: 0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "totalPost = 0\n",
    "accuracyPost = 0\n",
    "\n",
    "\n",
    "for i in range(0, len(dataset)):\n",
    "    totalPost += 1\n",
    "    image, label = dataset[i]\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    label = torch.tensor([label]).to(device)\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    # print(f\"Predicted: {predicted.item()}, Actual: {label.item()}\")\n",
    "    if(i % 1000 == 0):\n",
    "        print(f\"Slika: {i}\")\n",
    "    if predicted.item() == label.item():\n",
    "        accuracyPost += 1\n",
    "    \n",
    "\n",
    "print(f\"Accuracy: {accuracyPost/totalPost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ovo save-uje model\n",
    "torch.save(model.state_dict(), \"model_50epoch_coco_val_batch_size_384_acc_79.2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.mobilenet_v3_small(pretrained=True)\n",
    "model2.classifier[3] = nn.Linear(model2.classifier[3].in_features, 64)  \n",
    "model2 = model2.to(device)\n",
    "\n",
    "\n",
    "model2.train()\n",
    "\n",
    "for param in model2.features.parameters():\n",
    "\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "for param in model2.classifier.parameters():\n",
    "\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [10/61], Loss: 4.2363\n",
      "Epoch [1/50], Step [20/61], Loss: 4.1546\n",
      "Epoch [1/50], Step [30/61], Loss: 4.1426\n",
      "Epoch [1/50], Step [40/61], Loss: 4.0789\n",
      "Epoch [1/50], Step [50/61], Loss: 4.0633\n",
      "Epoch [1/50], Step [60/61], Loss: 4.0121\n",
      "Epoch [1/50], Average Loss: 4.1151, Time: 33.5041s\n",
      "Epoch [2/50], Step [10/61], Loss: 3.9519\n",
      "Epoch [2/50], Step [20/61], Loss: 3.9103\n",
      "Epoch [2/50], Step [30/61], Loss: 3.9291\n",
      "Epoch [2/50], Step [40/61], Loss: 3.8680\n",
      "Epoch [2/50], Step [50/61], Loss: 3.7918\n",
      "Epoch [2/50], Step [60/61], Loss: 3.8115\n",
      "Epoch [2/50], Average Loss: 3.8920, Time: 11.0812s\n",
      "Epoch [3/50], Step [10/61], Loss: 3.7200\n",
      "Epoch [3/50], Step [20/61], Loss: 3.7200\n",
      "Epoch [3/50], Step [30/61], Loss: 3.6952\n",
      "Epoch [3/50], Step [40/61], Loss: 3.7067\n",
      "Epoch [3/50], Step [50/61], Loss: 3.6115\n",
      "Epoch [3/50], Step [60/61], Loss: 3.6578\n",
      "Epoch [3/50], Average Loss: 3.7144, Time: 11.0041s\n",
      "Epoch [4/50], Step [10/61], Loss: 3.6658\n",
      "Epoch [4/50], Step [20/61], Loss: 3.5226\n",
      "Epoch [4/50], Step [30/61], Loss: 3.5905\n",
      "Epoch [4/50], Step [40/61], Loss: 3.4861\n",
      "Epoch [4/50], Step [50/61], Loss: 3.4664\n",
      "Epoch [4/50], Step [60/61], Loss: 3.4573\n",
      "Epoch [4/50], Average Loss: 3.5344, Time: 11.0993s\n",
      "Epoch [5/50], Step [10/61], Loss: 3.3919\n",
      "Epoch [5/50], Step [20/61], Loss: 3.3490\n",
      "Epoch [5/50], Step [30/61], Loss: 3.3657\n",
      "Epoch [5/50], Step [40/61], Loss: 3.3609\n",
      "Epoch [5/50], Step [50/61], Loss: 3.3582\n",
      "Epoch [5/50], Step [60/61], Loss: 3.2673\n",
      "Epoch [5/50], Average Loss: 3.3935, Time: 10.9164s\n",
      "Epoch [6/50], Step [10/61], Loss: 3.3220\n",
      "Epoch [6/50], Step [20/61], Loss: 3.1971\n",
      "Epoch [6/50], Step [30/61], Loss: 3.2405\n",
      "Epoch [6/50], Step [40/61], Loss: 3.1328\n",
      "Epoch [6/50], Step [50/61], Loss: 3.1769\n",
      "Epoch [6/50], Step [60/61], Loss: 3.2410\n",
      "Epoch [6/50], Average Loss: 3.2488, Time: 11.0199s\n",
      "Epoch [7/50], Step [10/61], Loss: 3.1740\n",
      "Epoch [7/50], Step [20/61], Loss: 3.1073\n",
      "Epoch [7/50], Step [30/61], Loss: 3.0773\n",
      "Epoch [7/50], Step [40/61], Loss: 3.0984\n",
      "Epoch [7/50], Step [50/61], Loss: 3.0921\n",
      "Epoch [7/50], Step [60/61], Loss: 3.0231\n",
      "Epoch [7/50], Average Loss: 3.1125, Time: 11.0588s\n",
      "Epoch [8/50], Step [10/61], Loss: 2.9882\n",
      "Epoch [8/50], Step [20/61], Loss: 2.9754\n",
      "Epoch [8/50], Step [30/61], Loss: 3.0072\n",
      "Epoch [8/50], Step [40/61], Loss: 2.9153\n",
      "Epoch [8/50], Step [50/61], Loss: 2.9862\n",
      "Epoch [8/50], Step [60/61], Loss: 2.9662\n",
      "Epoch [8/50], Average Loss: 2.9894, Time: 11.0528s\n",
      "Epoch [9/50], Step [10/61], Loss: 2.8767\n",
      "Epoch [9/50], Step [20/61], Loss: 2.8443\n",
      "Epoch [9/50], Step [30/61], Loss: 2.8418\n",
      "Epoch [9/50], Step [40/61], Loss: 2.9137\n",
      "Epoch [9/50], Step [50/61], Loss: 2.7790\n",
      "Epoch [9/50], Step [60/61], Loss: 2.7889\n",
      "Epoch [9/50], Average Loss: 2.8845, Time: 11.1373s\n",
      "Epoch [10/50], Step [10/61], Loss: 2.8011\n",
      "Epoch [10/50], Step [20/61], Loss: 2.6919\n",
      "Epoch [10/50], Step [30/61], Loss: 2.8098\n",
      "Epoch [10/50], Step [40/61], Loss: 2.7316\n",
      "Epoch [10/50], Step [50/61], Loss: 2.8308\n",
      "Epoch [10/50], Step [60/61], Loss: 2.6830\n",
      "Epoch [10/50], Average Loss: 2.7700, Time: 11.3846s\n",
      "Epoch [11/50], Step [10/61], Loss: 2.6414\n",
      "Epoch [11/50], Step [20/61], Loss: 2.6019\n",
      "Epoch [11/50], Step [30/61], Loss: 2.6346\n",
      "Epoch [11/50], Step [40/61], Loss: 2.6327\n",
      "Epoch [11/50], Step [50/61], Loss: 2.5941\n",
      "Epoch [11/50], Step [60/61], Loss: 2.5638\n",
      "Epoch [11/50], Average Loss: 2.6571, Time: 11.0953s\n",
      "Epoch [12/50], Step [10/61], Loss: 2.6144\n",
      "Epoch [12/50], Step [20/61], Loss: 2.6506\n",
      "Epoch [12/50], Step [30/61], Loss: 2.5993\n",
      "Epoch [12/50], Step [40/61], Loss: 2.5014\n",
      "Epoch [12/50], Step [50/61], Loss: 2.5634\n",
      "Epoch [12/50], Step [60/61], Loss: 2.5619\n",
      "Epoch [12/50], Average Loss: 2.5624, Time: 11.2135s\n",
      "Epoch [13/50], Step [10/61], Loss: 2.5025\n",
      "Epoch [13/50], Step [20/61], Loss: 2.5202\n",
      "Epoch [13/50], Step [30/61], Loss: 2.4977\n",
      "Epoch [13/50], Step [40/61], Loss: 2.4087\n",
      "Epoch [13/50], Step [50/61], Loss: 2.5111\n",
      "Epoch [13/50], Step [60/61], Loss: 2.4440\n",
      "Epoch [13/50], Average Loss: 2.5122, Time: 11.0330s\n",
      "Epoch [14/50], Step [10/61], Loss: 2.3943\n",
      "Epoch [14/50], Step [20/61], Loss: 2.3398\n",
      "Epoch [14/50], Step [30/61], Loss: 2.4399\n",
      "Epoch [14/50], Step [40/61], Loss: 2.3630\n",
      "Epoch [14/50], Step [50/61], Loss: 2.4208\n",
      "Epoch [14/50], Step [60/61], Loss: 2.4549\n",
      "Epoch [14/50], Average Loss: 2.4150, Time: 11.2227s\n",
      "Epoch [15/50], Step [10/61], Loss: 2.2437\n",
      "Epoch [15/50], Step [20/61], Loss: 2.4084\n",
      "Epoch [15/50], Step [30/61], Loss: 2.3587\n",
      "Epoch [15/50], Step [40/61], Loss: 2.4262\n",
      "Epoch [15/50], Step [50/61], Loss: 2.3086\n",
      "Epoch [15/50], Step [60/61], Loss: 2.3202\n",
      "Epoch [15/50], Average Loss: 2.3276, Time: 11.7280s\n",
      "Epoch [16/50], Step [10/61], Loss: 2.3879\n",
      "Epoch [16/50], Step [20/61], Loss: 2.4172\n",
      "Epoch [16/50], Step [30/61], Loss: 2.3100\n",
      "Epoch [16/50], Step [40/61], Loss: 2.2489\n",
      "Epoch [16/50], Step [50/61], Loss: 2.1899\n",
      "Epoch [16/50], Step [60/61], Loss: 2.4373\n",
      "Epoch [16/50], Average Loss: 2.3072, Time: 11.4049s\n",
      "Epoch [17/50], Step [10/61], Loss: 2.2713\n",
      "Epoch [17/50], Step [20/61], Loss: 2.2196\n",
      "Epoch [17/50], Step [30/61], Loss: 2.2689\n",
      "Epoch [17/50], Step [40/61], Loss: 2.2084\n",
      "Epoch [17/50], Step [50/61], Loss: 2.2620\n",
      "Epoch [17/50], Step [60/61], Loss: 2.2131\n",
      "Epoch [17/50], Average Loss: 2.2433, Time: 11.8608s\n",
      "Epoch [18/50], Step [10/61], Loss: 2.2513\n",
      "Epoch [18/50], Step [20/61], Loss: 2.1577\n",
      "Epoch [18/50], Step [30/61], Loss: 2.1799\n",
      "Epoch [18/50], Step [40/61], Loss: 2.0578\n",
      "Epoch [18/50], Step [50/61], Loss: 2.2067\n",
      "Epoch [18/50], Step [60/61], Loss: 2.2540\n",
      "Epoch [18/50], Average Loss: 2.1923, Time: 11.3449s\n",
      "Epoch [19/50], Step [10/61], Loss: 2.0525\n",
      "Epoch [19/50], Step [20/61], Loss: 2.0480\n",
      "Epoch [19/50], Step [30/61], Loss: 2.2152\n",
      "Epoch [19/50], Step [40/61], Loss: 2.0913\n",
      "Epoch [19/50], Step [50/61], Loss: 2.1795\n",
      "Epoch [19/50], Step [60/61], Loss: 2.1031\n",
      "Epoch [19/50], Average Loss: 2.1457, Time: 11.1096s\n",
      "Epoch [20/50], Step [10/61], Loss: 2.1793\n",
      "Epoch [20/50], Step [20/61], Loss: 1.9894\n",
      "Epoch [20/50], Step [30/61], Loss: 2.0239\n",
      "Epoch [20/50], Step [40/61], Loss: 1.9479\n",
      "Epoch [20/50], Step [50/61], Loss: 2.0841\n",
      "Epoch [20/50], Step [60/61], Loss: 2.0267\n",
      "Epoch [20/50], Average Loss: 2.1087, Time: 11.3589s\n",
      "Epoch [21/50], Step [10/61], Loss: 2.0044\n",
      "Epoch [21/50], Step [20/61], Loss: 1.9628\n",
      "Epoch [21/50], Step [30/61], Loss: 2.0859\n",
      "Epoch [21/50], Step [40/61], Loss: 2.1288\n",
      "Epoch [21/50], Step [50/61], Loss: 2.1349\n",
      "Epoch [21/50], Step [60/61], Loss: 2.0209\n",
      "Epoch [21/50], Average Loss: 2.0742, Time: 11.7471s\n",
      "Epoch [22/50], Step [10/61], Loss: 2.1210\n",
      "Epoch [22/50], Step [20/61], Loss: 2.0379\n",
      "Epoch [22/50], Step [30/61], Loss: 2.0459\n",
      "Epoch [22/50], Step [40/61], Loss: 1.9944\n",
      "Epoch [22/50], Step [50/61], Loss: 2.0217\n",
      "Epoch [22/50], Step [60/61], Loss: 1.9590\n",
      "Epoch [22/50], Average Loss: 2.0783, Time: 11.5550s\n",
      "Epoch [23/50], Step [10/61], Loss: 2.0744\n",
      "Epoch [23/50], Step [20/61], Loss: 1.9943\n",
      "Epoch [23/50], Step [30/61], Loss: 1.9669\n",
      "Epoch [23/50], Step [40/61], Loss: 1.9459\n",
      "Epoch [23/50], Step [50/61], Loss: 1.8764\n",
      "Epoch [23/50], Step [60/61], Loss: 2.1051\n",
      "Epoch [23/50], Average Loss: 2.0014, Time: 11.5608s\n",
      "Epoch [24/50], Step [10/61], Loss: 1.9863\n",
      "Epoch [24/50], Step [20/61], Loss: 1.9825\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.00002)\n",
    "\n",
    "train_model(model2, dataloader, criterion, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
